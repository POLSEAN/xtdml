---
title: "Introduction to XTDML: Estimating the Causal Effect in Parlailly Linear Panel Regression Models with Double Machine Learning"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to XTDML: Estimating the Causal Effect in Parlailly Linear Panel Regression Models with Double Machine Learning}
  %\VignetteEngine{knitr::rmarkdown}
---

### Introduction

This is a vignette that explains to use of the `XTDML` package.

`XTDML` package estimates the structural (causal) parameter using double machine learning (DML) with partially linear regression (PLR) models in the context of panel data with fixed effects (Clarke and Polselli, 2025).

The package allows the estimation of the nuisance functions by machine learning methods and the computation of the Neyman-orthogonal score functions. `XTDML` is built on the `DoubleML` package (Bach et al., 2024) using the `mlr3` ecosystem and the `R6` package.


### The Partially Linear Panel Regression Model
The `XTDML` package estimates the structural (causal) parameter of interest from panel data model below: 

\begin{align}
  Y_{it} &= \theta_0 D_{it} + g_0(X_{it}) + \alpha_i + U_{it}\\
  D_{it} &= m_0(X_{it}) + \gamma_i + V_i,
\end{align}

As an illustration, we use data generated inside the `XTDML` package from the model above,
where $U_{it} \sim \mathcal{N}(0,1)$, $V_{it}  \sim \mathcal{N}(0,1)$, $\alpha_i = \rho A_i + \sqrt{1-\rho^2} B_i$ with
$A_i\sim \mathcal{N}(3,3)$, $B_i\sim \mathcal{N}(0,1)$, and $\gamma_i\sim \mathcal{N}(0,5)$. $\theta_0$ is the structural (causal) parameter of interest to be estimated, whose value is decided by the user; default $\theta_0=0.5$. $\rho$ is the parameter governing the relationship between the unobserved individual heterogeneity $\alpha_i$ and the covariates $X_{it}$; default is $\rho=0.8$. 

The covariates are distributed as $X_{it,p} \sim A_i + \mathcal{N}(0, 5)$, where *p* is the number of covariates, chosen by the user; default is $p=10$.

The nuisance functions are generated as follows:

\begin{align}
m_0(X_{it}) = a_1 [X_{it,1} \times 1(X_{it,1}>0)] + a_2 [X_{it,1} \times X_{it,3}]\\
g_0(X_{it}) = b_1 [X_{it,1} \times X_{it,3}] + b_2 [X_{it,3} \times 1(X_{it,3}>0)],
\end{align}

with $a_1=b_2=0.25$ and $a_2=b_1=0.5$.


```{r}

# ML packages
library(XTDML) 
library(mlr3)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
library(mlr3misc)

# other packages
library(tibble) 
#library(datawizard)
library(data.table)


# To suppress messages
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")

# Set seed 
set.seed(1234)

# Load data
df = make_plpr_data(n_obs = 500, t_per = 10, dim_x = 10, theta = 0.5, rho=0.8)
head(df)

# Define X columns
x_cols = paste0("X", 1:10)

```

### Usage

The key steps for estimating the treatment effects using `XTDML` package are:

  1. Setting up the XTDML data environment
  2. Setting up the XTDML estimation environment
  3. Setting up the hyperparameter tuning
  4. Estimation with selected (tuned) hyperparameters

The three examples below use a regression tree (`rpart`), cross-validated Lasso (`cv_glmet`), and neural networks (`nnet`) to *learn* the nuisance functions `ml_l` and `ml_m`. 

In Stage 1 (data environment set up), the user can choose:

  1. The panel data approach to use among `approach = ("fd-exact", "wg-approx", "cre")`; default is `"fd-exact"`. `XTDML` proceeds with transforming the data based on the selected approach, following Clarke and Polselli (2025). 

  2. The type of transformation to apply to the covariates $X$ in the data set among
  `transformX = ("no", "minmax", "poly")`. `"no"` does not transform the covariates `X`
 and is recommended for tree-based learners. `"minmax"` applies the Min-Max normalization
 $x' = (x-x_{min})/(x_{max}-x_{min})$ to the covariates and is recommended with neural networks.
 `"poly"` add polynomials up to order three and interactions between all possible
 combinations of two and three variables; this is recommended for Lasso.
 Default is `"no"`.

These two options allow the user to immediately use `XTDML` estimation tools *without the need* to proceed with additional data managing and transformations.

## Example with Regression Tree (`rpart`)

```{r}
set.seed(1234)

# Set data environment
obj_xtdml_data = xtdml_data_from_data_frame(df,
                      x_cols = x_cols,  y_col = "y", d_cols = "d",
                      cluster_cols = "id",
                      approach = "cre", 
                      transformX = "no") # does not transform x_cols
obj_xtdml_data$print()

```

```{r}

set.seed(1234)

# Declare learner
learner = lrn("regr.rpart")
ml_l = learner$clone()
ml_m = learner$clone()

xtdml_rpart = xtdml_plr$new(obj_xtdml_data,
                            ml_l = ml_l, ml_m = ml_m,
                            n_folds = 5, score="orth-PO")

# set up a list of parameter grids
param_grid = list("ml_l" = ps(cp = p_dbl(lower = 0.01, upper = 0.02),
                              maxdepth = p_int(lower = 2, upper = 10)),
                  "ml_m" = ps(cp = p_dbl(lower = 0.01, upper = 0.02),
                              maxdepth = p_int(lower = 2, upper = 10))
                  )

tune_settings = list(n_folds_tune = 5,
                     rsmp_tune = mlr3::rsmp("cv", folds = 5),
                     terminator = mlr3tuning::trm("evals", n_evals = 10),
                     algorithm = tnr("grid_search"), resolution = 20)

xtdml_rpart$tune(param_set = param_grid, tune_settings = tune_settings)

# Estimate target/causal parameter
xtdml_rpart$fit()
xtdml_rpart$print()

# Print selected (tuned) hyperparameters
print(xtdml_rpart$params)

```

## Example with Cross-validated Lasso (`cv_glmnet`)

```{r}
set.seed(1234)


# Set data environment
obj_xtdml_data_lasso = xtdml_data_from_data_frame(df,
                      x_cols = x_cols,  y_col = "y", d_cols = "d",
                      cluster_cols = "id",
                      approach = "cre",
                      transformX = "poly") # creates extensive dictionary of nonlinear terms for x_cols
#obj_xtdml_data$print()

# Select learner

learner = lrn("regr.cv_glmnet", s="lambda.min")
ml_m = learner$clone()
ml_l = learner$clone()

# Set up estimation environment
xtdml_lasso = xtdml_plr$new(obj_xtdml_data_lasso,
                             ml_l = ml_l, ml_m = ml_m,
                             n_folds = 5)

# Display DML Estimates
xtdml_lasso$fit()
xtdml_lasso$print()

```

## Example with Neural Network (`nnet`)

```{r}
set.seed(1234)

# Set up data environment
obj_xtdml_data_nnet = xtdml_data_from_data_frame(df,
                                   x_cols = x_cols,  y_col = "y", d_cols = "d",
                                   cluster_cols = "id",
                                   approach = "cre",
                                   transformX = "minmax") # applied the minmax transformation to x_cols
#obj_xtdml_data_nnet$print()

# Declare learner
ml_l = lrn("regr.nnet", maxit=100, MaxNWts=1000, trace=FALSE)
ml_m = lrn("regr.nnet", maxit=100, MaxNWts=1000, trace=FALSE)

# Set up DML environment
xtdml_nnet = xtdml_plr$new(obj_xtdml_data_nnet,
                           ml_l = ml_l, ml_m = ml_m,
                           n_folds = 5)

# Hyperparameter tuning
# Set up a list of parameter grids
param_grid = list("ml_l" = ps(size = p_int(lower = 2, upper = 10),
                              decay = p_dbl(lower = 0, upper = 0.05)),
                  "ml_m" = ps(size = p_int(lower = 2, upper = 10),
                              decay = p_dbl(lower = 0, upper =  0.05))
                  )

# Set up minimum requirements for tuning settings
tune_settings = list(n_folds_tune = 5,
                     rsmp_tune = mlr3::rsmp("cv", folds = 5),
                     terminator = mlr3tuning::trm("evals", n_evals = 10),
                     algorithm = mlr3tuning::tnr("grid_search", resolution = 20))

xtdml_nnet$tune(param_set = param_grid, tune_settings = tune_settings)

# Fit DML model and print results
xtdml_nnet$fit()
xtdml_nnet$print()

```

## Results

The code below shows how to extract estimation results and display them in a customizable table.  

```{r}

# Display table that compares results
table = matrix(0, 3, 6)
table[1,] = c(xtdml_rpart$coef_theta,
              xtdml_rpart$se_theta,
              xtdml_rpart$pval_theta,
              xtdml_rpart$model_rmse,
              as.numeric(xtdml_rpart$rmses["ml_l"]),
              as.numeric(xtdml_rpart$rmses["ml_m"])
)
table[2,] = c(xtdml_lasso$coef_theta,
              xtdml_lasso$se_theta,
              xtdml_lasso$pval_theta,
              xtdml_lasso$model_rmse,
              as.numeric(xtdml_lasso$rmses["ml_l"]),
              as.numeric(xtdml_lasso$rmses["ml_m"])
)
table[3,] = c(xtdml_nnet$coef_theta,
              xtdml_nnet$se_theta,
              xtdml_nnet$pval_theta,
              xtdml_nnet$model_rmse,
              as.numeric(xtdml_nnet$rmses["ml_l"]),
              as.numeric(xtdml_nnet$rmses["ml_m"])
)

colnames(table)= c("Estimate", "Std. Error", "P-value", "Model RMSE", "MSE of l", "MSE of m")
rownames(table)= c("XTDML-TREE", "XTDML-LASSO", "XTDML-NNET")
print(table)
```
